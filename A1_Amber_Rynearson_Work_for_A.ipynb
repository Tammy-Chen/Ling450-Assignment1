{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3d4954f-0d5e-451e-a1ee-defc519df0ba",
   "metadata": {},
   "source": [
    "### Beginning Stuff (Importing Things)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2363dedb-2159-4ad9-9fa7-e341e34ce7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3a4e8-920d-4d9c-9d33-e1ada135b827",
   "metadata": {},
   "source": [
    "### Actual code 2\n",
    "\n",
    "Okay this is the og matcher code. maybe this is a better choice?\n",
    "\n",
    "Code/source taken from: http://spacy.pythonhumanities.com/02_02_matcher.html \n",
    "\n",
    "A lot of the explanation is in the above link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4103b902-e919-441c-8c7b-0a1b1a3d4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "###opening file (step 1)\n",
    "with open (\"A1_data/file_1.txt\", \"r\", encoding='utf-8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f28b7a0a-93bd-4293-971b-2573f6ea12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### step 2\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605795e8-c3b7-4f1a-aceb-115aaf57f35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n",
      "(3232560085755078826, 1, 3) CTV Vancouver\n",
      "(3232560085755078826, 6, 7) Abbotsford\n",
      "(3232560085755078826, 8, 9) B.C.\n",
      "(3232560085755078826, 25, 26) Africa\n",
      "(3232560085755078826, 42, 43) Kim\n",
      "(3232560085755078826, 44, 46) Clark Moran\n",
      "(3232560085755078826, 52, 53) Immigration\n",
      "(3232560085755078826, 54, 55) Refugees\n",
      "(3232560085755078826, 56, 58) Citizenship Canada\n",
      "(3232560085755078826, 72, 73) Ayo\n"
     ]
    }
   ],
   "source": [
    "### step 3 (PROPNs in order of the text)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409b97d-9302-42f1-8948-a54fa2de46ed",
   "metadata": {},
   "source": [
    "### what step 3 did\n",
    "\n",
    "step 3 was supposed to pull out all of the entities/proper nouns to see who potential speakers may be, in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a87c6661-fd16-424c-b797-27701299e921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "(3232560085755078826, 44, 47) Clark Moran received\n",
      "(3232560085755078826, 56, 59) Citizenship Canada informing\n",
      "(3232560085755078826, 109, 111) Kim told\n",
      "(3232560085755078826, 174, 176) Kim confirmed\n",
      "(3232560085755078826, 246, 248) Canada has\n",
      "(3232560085755078826, 395, 397) Clark headed\n",
      "(3232560085755078826, 508, 510) Kim said\n",
      "(3232560085755078826, 602, 604) Morans have\n",
      "(3232560085755078826, 614, 616) IRCC stressed\n",
      "(3232560085755078826, 633, 635) Kim said\n"
     ]
    }
   ],
   "source": [
    "### step 4 (what sequences show up with PROPN?)\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PROPN\", \"OP\": \"+\"}, {\"POS\": \"VERB\"}]\n",
    "matcher.add(\"PROPER_NOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32db36fb-c2b6-4bd5-aebf-558368744598",
   "metadata": {},
   "source": [
    "### What step 4 did\n",
    "\n",
    "This was supposed to pull out the common verbs coming after a proper noun in a text (often will indicate the speech verbs)\n",
    "\n",
    "step 5 does that same thing but with pronouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426c265e-3a74-420a-b35a-beb1845ec394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "(14866930662545315295, 78, 80) they adopted\n",
      "(14866930662545315295, 96, 98) it feels\n",
      "(14866930662545315295, 180, 182) I have\n",
      "(14866930662545315295, 354, 356) all adoptions\n",
      "(14866930662545315295, 481, 483) what happens\n",
      "(14866930662545315295, 484, 486) They send\n",
      "(14866930662545315295, 494, 496) They take\n",
      "(14866930662545315295, 658, 660) they weigh\n",
      "(14866930662545315295, 672, 674) it feels\n",
      "(14866930662545315295, 679, 682) what this means\n"
     ]
    }
   ],
   "source": [
    "###step 5\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PRON\", \"OP\": \"+\"}, {\"POS\": \"VERB\"}]\n",
    "matcher.add(\"PRONOUNS\", [pattern], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches = matcher(doc)\n",
    "matches.sort(key = lambda x: x[1])\n",
    "print (len(matches))\n",
    "for match in matches[:10]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef99282-9793-4d35-970d-3b23a09e6739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(16432004385153140588, 108, 133) \" Kim told CTV News Friday. \"The fact that we are being accused right now of an unethical adoption is crazy.\"\n",
      "(16432004385153140588, 173, 209) \" Kim confirmed, adding that \"I have no idea where that information came from because both Clark and I were there in the office with all of the workers from the orphanage.\"\n",
      "(16432004385153140588, 242, 274) \"the Government of Canada has obligations under international conventions to ensure children are not abducted, bought or sold, or removed from their biological families without legal consent.\"\n",
      "(16432004385153140588, 280, 309) \"in some cases, extra steps in the citizenship or immigration process may be needed to make sure the adoption meets all requirements of international adoption.\"\n"
     ]
    }
   ],
   "source": [
    "### step 6 (pull out quotes)\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern1 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"*\"}, {'IS_PUNCT': True, \"OP\": \"+\"}, {'ORTH': '\"'}, {'IS_PUNCT': True, \"OP\": \"*\"}]\n",
    "pattern2 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'POS': 'VERB', \"OP\": \"+\"}, {'POS': 'PROPN', \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'IS_PUNCT': True, \"OP\": \"*\"}]\n",
    "pattern3 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'POS': 'VERB', \"OP\": \"+\"}, {'POS': 'PROPN', \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}]\n",
    "pattern4 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'POS': 'PROPN', \"OP\": \"+\"}, {'POS': 'VERB', \"OP\": \"+\"}]\n",
    "pattern5 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'POS': 'PROPN', \"OP\": \"+\"}, {'POS': 'VERB', \"OP\": \"+\"}, {'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]  \n",
    "pattern6 = [{'POS': \"PROPN\", \"OP\": \"+\"},{'POS': 'VERB', \"OP\": \"+\"}, {'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "pattern7 = [{'POS':'PRON', \"OP\": \"+\"}, {'POS': 'VERB', \"OP\": \"+\"}, {'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "pattern8 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'POS': 'PRON', \"OP\": \"+\"}, {'POS': 'VERB', \"OP\": \"+\"}, {'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "pattern9 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}, {'POS': 'PRON', \"OP\": \"+\"},{'POS': 'VERB', \"OP\": \"+\"}]\n",
    "pattern10 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"+\"}, {'ORTH': '\"'}]\n",
    "pattern11 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"+\"}, {'ORTH': '\"'}, {'POS': 'VERB', \"OP\": \"+\"}, {'POS': 'PROPN', \"OP\": \"+\"} ]\n",
    "pattern12 = [{'ORTH': '\"'}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'IS_ALPHA': True, \"OP\": \"+\"}, {'IS_PUNCT': True, \"OP\": \"*\"}, {'ORTH': '\"'}]\n",
    "matcher.add(\"QUOTES\", [pattern1, pattern2, pattern3, pattern4, pattern5, pattern6, pattern7, pattern8, pattern9, pattern10, pattern11, pattern12], greedy='LONGEST')\n",
    "doc = nlp(text)\n",
    "matches_q = matcher(doc)\n",
    "matches_q.sort(key = lambda x: x[1])\n",
    "print (len(matches_q))\n",
    "for match in matches_q[:20]:\n",
    "    print (match, doc[match[1]:match[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b042bc3e-2481-415f-88ee-b093c7f98428",
   "metadata": {},
   "source": [
    "### Patterns in step 5\n",
    "\n",
    "pattern 1: quotation, words, punctuation, quotation, (pulls out \"xxx\" pattern, theoretically)\n",
    "\n",
    "pattern 2: quotation, words, punctuation, quotation, verb, proper noun, quotation, words, punctuation, quotation (looks for pattern \"xxx\" said person, \"xxx\")\n",
    "\n",
    "pattern 3: quotation, words, punctuation, quotation, verb, proper noun (\"xxx\" said person)\n",
    "\n",
    "pattern 4: quotation, words, punctuation, quotation, proper noun, verb (\"xxx\" person said)\n",
    "\n",
    "pattern 5: quotation, words, punctuation, quotation, proper noun, verb, quotation, words, punctuation, quotation (looks for pattern \"xxx\" \n",
    "person said \"xxx\")\n",
    "\n",
    "pattern 6: proper noun, verb, quotation, words, punctuation, quotation (person said \"xxx\")\n",
    "\n",
    "pattern 7: pronoun, verb, quotation, words, punctuation, quotation (person(pronoun) said \"xxx\")\n",
    "\n",
    "pattern 8: quotation, words, punctuation, quotation, pronoun, verb, quotation, words, punctuation, quotation (\"xxx\" pronoun said, \"xxx\")\n",
    "\n",
    "pattern 9: quotation, words, punctuation, quotation, pronoun, verb (\"xxx\" pronoun said)\n",
    "\n",
    "pattern 10: quotation, words, punctuation, words, punctuation, words, punctuation, quotation (\"xxx. xxx. xxx.\")\n",
    "\n",
    "pattern 11: quotation, words, punctuation, words, punctuation, words, punctuation, quotation, verb, person (\"xxx. xxx. xxx.\" said person)\n",
    "\n",
    "pattern 12: quotation words, punctuation, words, punctuation, quotation (\"xxx. xxx.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed89212-17eb-49f8-bf33-305eb333d85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
